{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to calibrate your neural network classifer:\n",
    "## Getting accurate probabilities from your neural network model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/nplan-io/kdd2020-calibration/blob/master/tutorial/KDD%202020%20-%20nPlan%20calibration%20session.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial we'll use the CIFAR-10 image dataset, and a classifier trained on it, to explore what model confidence calibration is, how we can measure it, and what methods we can put in place to rectify poorly calibrated models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import relevant modules\n",
    "from urllib.request import urlopen\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "import tensorflow.keras.utils\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.calibration import calibration_curve\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CIFAR10 data.\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CIFAR-10\n",
    "CIFAR-10 is a dataset containing a collection of images falling into 10 classes: airplanes, cars, birds, cats, deer, dogs, frogs, horses, ships, and trucks. It contains 60 000 low resolution (32x32) images and is often used to train ML and computer vision models. The low resolution allows for quick testing of different models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x_train[112,])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to do some preprocessing of the data. This will allow our model to achieve higher accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data.\n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255\n",
    "\n",
    "# If subtract pixel mean from each image\n",
    "x_train_mean = np.mean(x_train, axis=0)\n",
    "x_train -= x_train_mean\n",
    "x_test -= x_train_mean\n",
    "\n",
    "y_train = tensorflow.keras.utils.to_categorical(y_train, 10)\n",
    "y_test = tensorflow.keras.utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The model\n",
    "Next step would be training the model but as we have limited time and resources, we will be using pre-trained [Keras ResNet model](https://keras.io/examples/cifar10_resnet/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Model(<some layers>)\n",
    "# ...\n",
    "# model.fit(x_train, y_train)\n",
    "# ...\n",
    "# model.evaluate(x_test,y_test)\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download, load and predict using the pretrained model\n",
    "h5file = tensorflow.keras.utils.get_file('/tmp/KDD_model_1.h5',\n",
    "         'https://raw.githubusercontent.com/nplan-io/kdd2020-calibration/master/tutorial/cifar10_resnet.h5')\n",
    "model = load_model(h5file)\n",
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_score = accuracy_score(np.argmax(y_test,1),np.argmax(y_pred,1))\n",
    "loss_score = log_loss(y_test, y_pred)\n",
    "print('Test accuracy is {0:.2f}, test loss is {1:.2f}'.format(acc_score, loss_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Understanding and measuring calibration - binary problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we consider our model as a binary classifier for illustration: either an image is in class 0 (airplanes), or it isn't. We can simplify our labels and predictions as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels:\n",
    "y_test_0 = [1 if y_val==0 else 0 for y_val in np.argmax(y_test, axis=1)]\n",
    "\n",
    "# Predictions:\n",
    "y_pred_0 = np.apply_along_axis(lambda row: row[0]==max(row), 1, y_pred)\n",
    "\n",
    "acc_score_0 = accuracy_score(y_test_0,y_pred_0)\n",
    "loss_score_0 = log_loss(y_test_0, y_pred_0)\n",
    "print('Test accuracy is {0:.2f}, test loss is {1:.2f}'.format(acc_score_0, loss_score_0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Reliability diagrams\n",
    "Can you use `calibration_curve()` from scikit-learn to show how calibrated the model is on our data? How would you interpret the results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE\n",
    "\n",
    "prob_true, prob_pred = ([0],[0])\n",
    "n_bins_0 = len(prob_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Expected calibration error\n",
    "Given the explanation of ECE, can you calculate the error for our dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# complete this function to calculate ece\n",
    "def ece_calculation_binary(prob_true, prob_pred, bin_sizes):\n",
    "    ### YOUR CODE HERE\n",
    "    pass\n",
    "\n",
    "# print the calculated ece2\n",
    "pred_hist_0 = np.histogram(a=y_pred_0, range=(0, 1), bins=n_bins_0)[0]     \n",
    "print(ece_calculation_binary(prob_true, prob_pred, pred_hist_0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Maximum calibration error\n",
    "Given the explanation of MCE, can you calculate it for our model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# complete this function to calculate mce\n",
    "def mce_calculation_binary(prob_true, prob_pred):\n",
    "    ### YOUR CODE HERE \n",
    "    pass\n",
    "\n",
    "#print the calculated mce\n",
    "print(mce_calculation_binary(prob_true, prob_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Root mean square calibration error\n",
    "Given the explanation, can you calculate RMSCE for our data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# complete this function to calculate rmsce\n",
    "def rmsce_calculation_binary(prob_true, prob_pred, bin_sizes):\n",
    "    ### YOUR CODE HERE \n",
    "    pass\n",
    "\n",
    "# print the calculated rmsce\n",
    "print(rmsce_calculation_binary(prob_true, prob_pred, pred_hist_0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Multiclass problems\n",
    "Extending the definition of these metrics, we can use them for multiclass classifiers, too. Can you show the reliability diagrams and calculate the calibration errors for the 10 classes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE\n",
    "\n",
    "\n",
    "def ece_calculation_multiclass():\n",
    "    ### use calibration_curve and your binary function to complete this function\n",
    "    pass\n",
    "    \n",
    "def mce_calculation_multiclass():\n",
    "    ### use calibration_curve and your binary function to complete this function\n",
    "    pass\n",
    "    \n",
    "def rmsce_calculation_multiclass():\n",
    "    ### use calibration_curve and your binary function to complete this function\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Post-training calibration methods - binary problems\n",
    "One way to mitigate a poorly calibrated model is through a post-hoc calibration method. In general, we seek a function to translate some output of our model into a calibrated probability. These come in several flavours - first we look at the binary problem, as before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Non-parametric methods (Isotonic regression)\n",
    "Given the description of isotonic regression, can you fit a stepwise constant, monotonically increasing function to the bucketed softmax data? Again, scikit-learn may be useful. Plot your result on the reliability diagram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Platt scaling\n",
    "Now, based on the explanation, can you implement binary platt scaling for our binary classifier? How did it improve the calibration? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Calibrating multiclass models\n",
    "\n",
    "Extending to the multiclass case is not simple. Several methods have been suggested, which include treating each class as a one-vs-all binary problem, calibrating it, and then normalising the new calibrated values across classes. Another idea is to generalise Platt Scaling from a one dimensional linear optimisation problem - we will discuss this below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Keras example -  temperature scaling\n",
    "A very simple generalisation of Platt scaling is to tune a single parameter based on the logits of the network, in order to try to optimise NLL - this is temperature scaling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to define a Keras layer that does the transformation we want:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "class TemperatureLayer(tensorflow.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    A keras layer that divides the input tensor elementwise by a single trainable parameter\n",
    "    temp_weight\n",
    "    \"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        \"\"\"\n",
    "        Initialises layer with weight param\n",
    "        \"\"\"\n",
    "        self.temp_weight = None\n",
    "        super(TemperatureLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        \"\"\"\n",
    "        Defines the trainable parameters of the model\n",
    "        \"\"\"\n",
    "        self.temp_weight = self.add_weight(\n",
    "            name=\"temp\",\n",
    "            shape=(1,),\n",
    "            initializer='one'\n",
    "        )\n",
    "        super(TemperatureLayer, self).build(input_shape)\n",
    "        \n",
    "    def call(self, in_tensor):\n",
    "        \"\"\"\n",
    "        Divide input tensor by constant t\n",
    "        \"\"\"\n",
    "        return tf.divide(in_tensor, self.temp_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can take our trained model and insert the temperature layer prior to the softmax output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = model\n",
    "# remove the original softmax\n",
    "new_model.layers.pop()\n",
    "# pipe the intermediate output through our new layer\n",
    "output = new_model.layers[-1].output\n",
    "output = TemperatureLayer(name=\"calibration\", trainable=False)(output)\n",
    "# add the softmax again\n",
    "output = tf.keras.layers.Activation('softmax', name='new_softmax')(output)\n",
    "# rebuild the model\n",
    "new_model = tf.keras.Model(inputs=new_model.input, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can see when we  that we've inserted the layer into the model\n",
    "new_model.layers[-5:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to fix our pretrained weights, allow the calibration weights to be trained, and recompile the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in new_model.layers:\n",
    "    if \"calibration\" in layer.name:\n",
    "        layer.trainable = True\n",
    "    else:\n",
    "        layer.trainable = False\n",
    "\n",
    "new_model.compile(optimizer=\"Adam\",\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now train the model using Keras `model.fit` - and only our calibration layer weights will be trained!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.fit(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the reliability diagrams and use your metric calculators to calculate the calibration metrics for this new model\n",
    "# have they improved?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Implementing a scaling layer\n",
    "Now it's your turn. Implement and evaluate a calibration method on the multiclass classifier. Based on the explanations you can use either matrix or vector platt layer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Complete this class to encapsulate the vector or matrix scaling logic as explained in the presentation\n",
    "\n",
    "# (hint - keras.layers.Dense may help for matrix platt!)\n",
    "class MyCalLayer(tf.keras.layers.Layer):\n",
    "    \"\"\" A template keras layer \"\"\"\n",
    "    \n",
    "    def __init__(self, **kwargs):\n",
    "        \"\"\" Initialises layer with weight params \"\"\"\n",
    "        ###\n",
    "        # initialise weight variables here\n",
    "        ###\n",
    "        super(MyCalLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        \"\"\" Defines the trainable parameters of the model \"\"\"\n",
    "        ###\n",
    "        # add keras weight objs of the correct shape to\n",
    "        # the respective varibles here\n",
    "        ###\n",
    "        super(MyCalLayer, self).build(input_shape)\n",
    "        \n",
    "    def call(self, in_tensor):\n",
    "        \"\"\" undertakes layer transformation \"\"\"\n",
    "        ###\n",
    "        # use the relevant tf functions to manipulate \n",
    "        # tensors as required, and return result\n",
    "        ###\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# follow the steps of the temperature scaling example above to calibrate and evaluate your model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
